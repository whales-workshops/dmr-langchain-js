# docker compose up --build --no-log-prefix
services:

  mcp-gateway:
    # mcp-gateway secures your MCP servers
    image: docker/mcp-gateway:latest
    ports:
      - 9011:9011
    #use_api_socket: true
    command:
      - --port=9011
      - --transport=streaming
      - --verbose
      - --catalog=/config/catalog.yaml
      - --servers=mcp-pizzerias,mcp-crazy-hawaiian-pizzas
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./config:/config
    depends_on:
      mcp-pizzerias:
        condition: service_healthy
      mcp-crazy-hawaiian-pizzas:
        condition: service_healthy


  mcp-pizzerias:
    build:
      context: mcp-pizzerias-server
      dockerfile: Dockerfile    
    environment:
      MCP_HTTP_PORT: 6060
    
    volumes:
      - ./mcp-pizzerias-server/data:/app/data

    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:6060/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  mcp-crazy-hawaiian-pizzas:
    build:
      context: mcp-crazy-hawaiian-pizzas-server
      dockerfile: Dockerfile    
    environment:
      MCP_HTTP_PORT: 6060
    
    volumes:
      - ./mcp-crazy-hawaiian-pizzas-server/data:/app/data

    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:6060/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s



  pizza-expert-with-mcp:
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      TERM: xterm-256color
      MCP_SERVER_BASE_URL: http://mcp-gateway:9011

      HISTORY_MESSAGES: 3
      OPTION_TEMPERATURE: 0.0
      # OPTION_REPEAT_LAST_N: 2
      # OPTION_REPEAT_PENALTY: 2.2
      # OPTION_TOP_P: 0.5
      # OPTION_TOP_K: 10      

      SYSTEM_INSTRUCTIONS_PATH: /app/settings/system-instructions.md
      CONTENT_PATH: /app/data    

    volumes:
      - ./data:/app/data
      - ./settings:/app/settings

    stdin_open: true   # docker run -i
    tty: true          # docker run -t
    restart: unless-stopped
    models:
      chat-model:
        endpoint_var: MODEL_RUNNER_BASE_URL
        model_var: MODEL_RUNNER_LLM_CHAT
      embedding-model:
        endpoint_var: MODEL_RUNNER_BASE_URL
        model_var: MODEL_RUNNER_EMBEDDING

models:
  chat-model:
    #model: ai/qwen2.5:0.5B-F16
    model: hf.co/menlo/jan-nano-gguf:q4_k_m   
  embedding-model:
    #model: ai/mxbai-embed-large
    model: ai/granite-embedding-multilingual:latest

# x-bake:
#   enabled: false